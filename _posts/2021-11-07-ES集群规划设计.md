# 1. 前言

​        最近系统性的看了一个ES的课程，刚好之前做了一次云ES的迁移。之前的文章有侧重讲了一下迁移的经过，这篇文章主要是想结合这个课程，讲一下整个ES集群的规划设计。



# 2. 业务特点

​        在考虑ES集群设计的时候，最重要的当然是业务场景，业务场景在读写方面的要求与特点，直接决定了ES集群的节点的部署与设计。那么怎么来量化评估业务的特点，我们可以重点关注以下几点：

1. 读写性能

   - 每秒写入量
   - 每秒查询量
   - 查询耗时
   - 数据准实时性要求秒级？分钟级？

2. 数据特点、mapping设计以及查询方式

   - 是否有冷热数据

   - 数据格式，字段设计

   - 查询类型（是否涉及聚合、深度翻页、模糊查询等等

     

    我们可以大致的把常见的场景分为搜索类和日志类，他们的特点和常见配置参考如下：

|          | 搜索类应用                                                   | 日志类应用                                                   |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **特点** | 数据量恒定，或者膨胀速度较慢。查询较为复杂多样，且QPS较高。是读多写少的应用类型，计算资源主要消耗在查询过程上，较难预先评估，结合压测更准确。 | 数据量膨胀速度快，并且按照时间分割，有冷热数据之分。是典型的写多读少的应用类型，计算资源主要消耗在写入过程中，较好估计，有经验值。 |
| **配置** | 涉及到搜索，最好上SSD，经验值建议按照1：10配置内存和硬盘。   | 可以考虑使用机械硬盘，根据腾讯云的经验值，热数据内存与磁盘的比例是1：96，冷数据内存与磁盘的比例是1：480，2核8G可以支持0.5万/秒的写入 |

​           

# 3. 集群设计

## 3.1 节点部署

ES的节点有以下几种类型：

| 节点类型        | 作用                                                         |
| --------------- | ------------------------------------------------------------ |
| Master Eligible | 主节点负责索引的创建和删除，跟踪集群的节点，决定给哪些节点分配哪些分片。主节点的个数上需要注意一下，防止脑裂的问题出现 |
| Data Node       | 负责存储数据，执行CRUD等操作                                 |
| Ingest Node     | 负责数据处理转换的节点，支持pipeline管道，可以将数据进行过滤，转换等操作 |
| Coordinate Node | 负责query + fetch操作，将搜索请求转发到数据节点上，将每个数据节点的返回值进行汇总处理 |

​    之前我们业务的节点全部是混部的，主节点和数据节点放在一起，整个集群的稳定性和性能都不高。而独立部署职责明确，每种类型的节点根据其特点可以选择不同的机型，无论从资源、性能还是稳定性上来说，都是很有利的。

​    一般来说，主节点需要独立部署，且主节点的数量设置最少为3个，可以选择部署在不同的可用区，这样子当某个机房或者机器出现问题的时候，ES能很快进行选主，且不会产生脑裂的情况。

​    Ingest Node可以用来做ETL的工作，这部分功能我们暂时没有用到。

​    如果查询较为复杂，建议单独部署coordinate node,  以防占用数据节点的CPU，内存等开销。



 ##  3.2 容量规划，分片、副本数设定

### 3.2.1  容量规划

​    一般来说存储资源的规划是较为好计算的，而计算资源由于查询的复杂性，一般需要配合压测来调整。

​       根据腾讯云的文档，影响 ES 服务存储容量的主要因素如下：

- 副本数量：副本有利于增加数据的可靠性，但同时会增加存储成本。默认和建议的副本数量为1，对于部分可以承受异常情况导致数据丢失的场景，可考虑设置副本数量为0。
- 数据膨胀：除原始数据外，ES 需要存储索引、列存数据等，在应用编码压缩等技术后，一般膨胀10%。
- 内部任务开销：ES 占用约**20%**的磁盘空间，用于 segment 合并、ES Translog、日志等。
- 操作系统预留：Linux 操作系统默认为 root 用户预留5%的磁盘空间，用于关键流程处理、系统恢复、防止磁盘碎片化问题等。

```
 实际空间 = 源数据 × (1 + 副本数量) × (1 + 数据膨胀) / (1 - 内部任务开销) / (1 - 操作系统预留)
        ≈ 源数据 × (1 + 副本数量) × 1.45
```

​    为保证服务的稳定运行，建议至少预留15%的存储空间，因此建议申请的存储容量为：

```
 存储容量 = 源数据 × (1 + 副本数量) × 1.45 × （1 + 预留空间）
        ≈ 源数据 × (1 + 副本数量) × 1.67
        
```

​     我们应用本身存储的是客户相关的数据，每秒写入量峰值大概为3000次/秒，查询为1W+/秒，主要瓶颈在查询上。未上云迁移前，全部索引的数据量大概是300G左右，预留100%的增长空间，就是600G（已经包含了上述的损耗和开销）



   ### 3.2.2  分片数、副本数的设定

​      大致确定了存储量后，选定了机型和节点数后，我们来考虑分片数和副本数的设定。

​      每个分片都是lucene的一个索引，所以每个分片都会占用一定的机器资源。分片数过小，后续无法通过增加节点水平扩展，单个分片的数据过大，也会导致rebalancing较慢，占用过多资源。而分片数过多，over-sharding会导致搜索打分不准确，单个节点上分片过多也会影响性能。可以遵循以下几个原则：

1.  单个分片的数据量在10G~50G左右，搜索场景可以小于20G，日志场景可以小于50G

2.  如果分片数超过数据节点数，建议分片数为节点数的倍数，可以使节点数更加平均分布

3.  根据存储/节点个数初步算出的分片数，可以在压测中动态调整，以获取最好的性能。

    

   副本数，后续可以动态调整。副本数会降低数据的索引速度，消耗节点的内存和CPU资源。但是适当增加副本数，有利于获得更好的读性能（吞吐量）。

   

## 3.3 索引设计

​      mapping的设计最重要的还是要根据业务的需求来定，这里我们只说几个原则在设计的时候注意下：

1.  想清楚这个字段是否需要分词，ES默认会给文本设置多字段的类型（text + keyword类型子字段），如果不  需要的话最好显式制定，提高性能。
2.  数值化类型，尽量选择贴近的，能用Byte就不用Long，优化存储，提高性能
3.  是否需要存储字段的原始字段/是否需要排序聚合等，有一些参数可以调整







